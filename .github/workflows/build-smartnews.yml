name: Fetch and Clean RSS Feed

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      
      - name: Install dependencies
        run: |
          pip install lxml requests beautifulsoup4
      
      - name: Fetch and Clean RSS Feed
        run: |
          python3 << 'EOF'
          import requests
          from lxml import etree
          from bs4 import BeautifulSoup
          from datetime import datetime, timezone
          import re

          response = requests.get('https://www.cabletv.com/feed')
          root = etree.fromstring(response.content)
          channel = root.find('channel')
          items = channel.findall('item')[:8]
          
          nsmap = {
              'content': 'http://purl.org/rss/1.0/modules/content/',
              'dc': 'http://purl.org/dc/elements/1.1/',
              'media': 'http://search.yahoo.com/mrss/',
              'snf': 'http://www.smartnews.be/snf'
          }
          
          for prefix, uri in nsmap.items():
              etree.register_namespace(prefix, uri)
          
          fallback = 'https://ctv-clearlink.github.io/RSS-Feed/CableTV.com%20RSS%20Logo%20Header.png'
          
          xml = ['<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:snf="http://www.smartnews.be/snf"><channel>']
          xml.append(f'<snf:logo><url>{fallback}</url></snf:logo>')
          
          for elem in channel:
              if elem.tag == 'item':
                  break
              if 'logo' not in elem.tag.lower():
                  xml.append(etree.tostring(elem, encoding='unicode'))
          
          print("Processing items...")
          for idx, item in enumerate(items):
              link = item.find('link').text.split('?')[0]
              print(f"\n{idx+1}. {link}")
              
              # Default fallback values from RSS
              title = item.find('title').text
              image = fallback
              
              # Get RSS content as fallback
              rss_content = ''
              for elem in item:
                  if elem.tag == '{http://purl.org/rss/1.0/modules/content/}encoded':
                      rss_content = elem.text or ''
                      break
              
              content = rss_content
              
              # FETCH PAGE FOR FULL TITLE, IMAGE AND CONTENT
              try:
                  print(f"  Fetching page...")
                  r = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
                  
                  if r.status_code == 200:
                      soup = BeautifulSoup(r.text, 'html.parser')
                      
                      # Get FULL title from og:title
                      og_title = soup.find('meta', property='og:title')
                      if og_title and og_title.get('content'):
                          title = og_title.get('content')
                          print(f"  ✓ Title: {title}")
                      
                      # Get image from og:image
                      og_image = soup.find('meta', property='og:image')
                      if og_image and og_image.get('content'):
                          img = og_image.get('content')
                          if 'logo' not in img.lower() and 'icon' not in img.lower():
                              image = img
                              print(f"  ✓ Image: {img.split('/')[-1]}")
                      
                      # Get FULL article content
                      article = soup.find('article')
                      if article:
                          # Clean it
                          for tag in article.find_all(['script', 'style', 'nav', 'footer', 'header']):
                              tag.decompose()
                          for form in article.find_all('form'):
                              form.decompose()
                          # Remove newsletter sections
                          for div in article.find_all(['div', 'section']):
                              classes = div.get('class', [])
                              if classes and any('newsletter' in c or 'subscribe' in c for c in classes):
                                  div.decompose()
                          
                          content = str(article)
                          print(f"  ✓ Content: {len(content)} chars")
                      else:
                          print(f"  ! No article tag found, using RSS content")
                  else:
                      print(f"  ! HTTP {r.status_code}")
                      
              except Exception as e:
                  print(f"  ! Error: {e}")
              
              # Build item
              xml.append('<item>')
              xml.append(f'<title><![CDATA[{title}]]></title>')
              
              # Add other RSS elements
              for elem in item:
                  tag = elem.tag
                  if tag == 'title':
                      continue
                  if tag == '{http://purl.org/rss/1.0/modules/content/}encoded':
                      continue
                  if tag.startswith('{http://search.yahoo.com/mrss/}'):
                      continue
                  xml.append(etree.tostring(elem, encoding='unicode'))
              
              xml.append(f'<content:encoded><![CDATA[{content}]]></content:encoded>')
              
              if item.find('{http://purl.org/dc/elements/1.1/}creator') is None:
                  xml.append('<dc:creator>CableTV.com</dc:creator>')
              if item.find('pubDate') is None:
                  xml.append(f'<pubDate>{datetime.now(timezone.utc).strftime("%a, %d %b %Y %H:%M:%S +0000")}</pubDate>')
              
              xml.append(f'<media:thumbnail url="{image.replace("&", "&amp;")}"/>')
              xml.append('</item>')
          
          xml.append('</channel></rss>')
          final = ''.join(xml).replace('https://www.cabletv.com/feed', 'https://ctv-clearlink.github.io/RSS-Feed/feed.xml')
          
          with open('feed.xml', 'w') as f:
              f.write(final)
          
          print(f"\n✓ Done: {len(final):,} bytes")
          EOF
      
      - name: Check for changes
        id: changes
        run: |
          git diff --quiet feed.xml || echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push feed
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git config user.name "github-actions[bot]"
          git add feed.xml
          git commit -m "Update feed"
          git pull --rebase origin main
          git push origin main
